‚è∫ Aqu√≠ est√° el contenido completo del README.md:

  # üéì Predicci√≥n de Puntajes ICFES - Sistema MLOps en Producci√≥n

  Sistema completo de Machine Learning para predecir puntajes del examen ICFES con precisi√≥n del 98.4%. Implementa pipeline
  MLOps end-to-end con versionado de datos, experimentaci√≥n sistem√°tica, CI/CD automatizado y deployment en producci√≥n.

  [![Python](https://img.shields.io/badge/Python-3.9-blue.svg)](https://www.python.org/)
  [![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
  [![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
  [![MLflow](https://img.shields.io/badge/MLflow-Tracking-orange.svg)](https://mlflow.org/)
  [![DVC](https://img.shields.io/badge/DVC-S3-purple.svg)](https://dvc.org/)

  ---

  ## üìñ Descripci√≥n del Proyecto

  ### Objetivo
  Predecir el puntaje global del examen ICFES (prueba estandarizada colombiana) bas√°ndose en los puntajes de las √°reas
  individuales evaluadas.

  ### Variables
  **Features de entrada (5):**
  - Razonamiento Cuantitativo (0-100)
  - Lectura Cr√≠tica (0-100)
  - Competencias Ciudadanas (0-100)
  - Ingl√©s (0-100)
  - Comunicaci√≥n Escrita (0-100)

  **Target:**
  - Puntaje Global (0-500)

  ### Dataset
  - **Registros:** ~9,000 estudiantes
  - **Tama√±o:** 8.1 MB
  - **Almacenamiento:** AWS S3 (versionado con DVC)

  ### Rendimiento del Modelo
  - **Algoritmo:** RandomForest (seleccionado autom√°ticamente)
  - **R¬≤ Score:** 98.4%
  - **MAE:** ~5 puntos
  - **Optimizaci√≥n:** 50 trials con Optuna (b√∫squeda bayesiana)

  ---

  ## üèóÔ∏è Stack MLOps

  ### Versionado y Almacenamiento
  - **Git:** Control de versiones del c√≥digo
  - **DVC (Data Version Control):** Versionado de datos y modelos
  - **AWS S3:** Almacenamiento remoto (bucket: `proyecto-icfes-data`)

  ### Experimentaci√≥n y Entrenamiento
  - **Optuna:** Optimizaci√≥n bayesiana de hiperpar√°metros
  - **MLflow:** Tracking de experimentos, m√©tricas y par√°metros
  - **scikit-learn:** Pipeline de ML con StandardScaler
  - **XGBoost:** Algoritmo de gradient boosting

  ### API y Deployment
  - **FastAPI:** Framework de API REST de alto rendimiento
  - **Uvicorn:** Servidor ASGI
  - **Pydantic:** Validaci√≥n de datos

  ### DevOps
  - **Docker:** Containerizaci√≥n de la aplicaci√≥n
  - **GitHub Actions:** Pipeline CI/CD automatizado
  - **Render:** Plataforma de deployment cloud
  - **Docker Hub:** Registro de im√°genes

  ---

  ## üîÑ Pipeline MLOps Implementado

  El proyecto implementa un ciclo MLOps completo:

  **1. Versionado de Datos**
  - DVC trackea datasets y modelos en S3
  - Git trackea c√≥digo y archivos .dvc
  - Reproducibilidad garantizada con hashes

  **2. Experimentaci√≥n Sistem√°tica**
  - MLflow registra todos los experimentos
  - Optuna optimiza hiperpar√°metros autom√°ticamente
  - Comparaci√≥n de 3 algoritmos: RandomForest, GradientBoosting, XGBoost

  **3. Entrenamiento Automatizado**
  - Pipeline de limpieza de datos
  - Cross-validation de 5 folds
  - M√©tricas completas: R¬≤, MAE, RMSE, MAPE
  - Selecci√≥n autom√°tica del mejor modelo

  **4. CI/CD Automatizado**
  - GitHub Actions trigger en push a main
  - DVC pull para descargar datos/modelos
  - Entrenamiento autom√°tico del modelo
  - Build y push de imagen Docker
  - Deploy autom√°tico a Render

  **5. Serving en Producci√≥n**
  - API REST con FastAPI
  - Health checks para load balancers
  - Validaci√≥n autom√°tica de inputs/outputs
  - Logging estructurado

  ---

  ## üöÄ Quick Start para Desarrolladores

  ### Prerequisitos
  ```bash
  # Instalar dependencias del sistema
  brew install python@3.9  # macOS
  sudo apt install python3.9  # Ubuntu

  # Instalar DVC
  pip install dvc dvc-s3

  Setup del Proyecto

  # 1. Clonar repositorio
  git clone <repository-url>
  cd predecir_puntaje_icfes

  # 2. Crear entorno virtual
  python3 -m venv venv
  source venv/bin/activate  # Linux/Mac
  # venv\Scripts\activate   # Windows

  # 3. Instalar dependencias
  pip install -r requirements.txt

  # 4. Configurar AWS (solo primera vez)
  dvc remote modify s3_remote access_key_id YOUR_AWS_KEY
  dvc remote modify s3_remote secret_access_key YOUR_AWS_SECRET

  # 5. Descargar datos y modelos
  dvc pull

  ---
  üìò Manual de Uso

  1. Entrenar Modelo Localmente

  # Descargar datos de entrenamiento
  dvc pull data/raw/data_train.csv.dvc

  # Instalar dependencias
  pip install -r requirements.txt

  # Ejecutar entrenamiento
  python train_model/train_model.py

  ¬øQu√© hace el script?
  1. Carga y limpia datos con DataPipeline
  2. Split 80/20 (train/test)
  3. Optimiza hiperpar√°metros (50 trials √ó 3 modelos)
  4. Entrena con mejores par√°metros
  5. Eval√∫a con 5-fold CV
  6. Registra en MLflow
  7. Guarda mejor modelo en models/best_model.pkl

  Tiempo estimado: 5-10 minutos

  Archivos generados:
  - models/best_model.pkl - Modelo serializado
  - models/model_metadata.pkl - Metadata (m√©tricas, params, git hash)
  - plots_temp/*.png - Gr√°ficas de optimizaci√≥n
  - mlruns/ - Experimentos MLflow

  ---
  2. Versionar Cambios (DVC + Git)

  # Despu√©s de entrenar un nuevo modelo
  dvc add models/best_model.pkl
  dvc add models/model_metadata.pkl

  # Commit archivos .dvc
  git add models/*.dvc
  git commit -m "Update model - improved R2 to 98.5%"

  # Push modelo a S3
  dvc push

  # Push c√≥digo a GitHub
  git push origin main

  Beneficios:
  - Modelos rastreables por hash
  - Recuperaci√≥n de cualquier versi√≥n anterior
  - Colaboraci√≥n sin conflictos en archivos grandes

  ---
  3. Correr API en Local

  Opci√≥n A: Python directo (Desarrollo)
  # Asegurarse de tener modelos descargados
  dvc pull

  # Iniciar servidor de desarrollo
  uvicorn api.app:app --reload --port 8000

  Opci√≥n B: Docker (Producci√≥n)
  # Descargar modelos
  dvc pull

  # Build imagen
  docker build -t icfes-api .

  # Run contenedor
  docker run -p 8000:8000 icfes-api

  Verificar API:
  # Health check
  curl http://localhost:8000/health

  # Documentaci√≥n interactiva
  open http://localhost:8000/docs

  ---
  4. Hacer Predicciones

  Usando cURL:
  curl -X POST http://localhost:8000/predict/ \
    -H "Content-Type: application/json" \
    -d '{
      "MOD_RAZONA_CUANTITATIVO_PNAL": 75,
      "MOD_LECTURA_CRITICA_PNAL": 80,
      "MOD_COMPETEN_CIUDADA_PNAL": 70,
      "MOD_INGLES_PNAL": 65,
      "MOD_COMUNI_ESCRITA_PNAL": 72
    }'

  Respuesta:
  {
    "prediction": 285.4
  }

  Usando Python:
  import requests

  response = requests.post(
      "http://localhost:8000/predict/",
      json={
          "MOD_RAZONA_CUANTITATIVO_PNAL": 75,
          "MOD_LECTURA_CRITICA_PNAL": 80,
          "MOD_COMPETEN_CIUDADA_PNAL": 70,
          "MOD_INGLES_PNAL": 65,
          "MOD_COMUNI_ESCRITA_PNAL": 72
      }
  )
  print(response.json())

  ---
  5. Explorar Experimentos con MLflow

  # Iniciar MLflow UI
  mlflow ui --backend-store-uri file:./mlruns

  # Abrir en navegador
  open http://localhost:5000

  Features de MLflow UI:
  - Comparar m√∫ltiples runs
  - Visualizar m√©tricas (R¬≤, MAE, RMSE)
  - Ver hiperpar√°metros utilizados
  - Descargar artifacts (gr√°ficas, modelos)
  - Filtrar por tags (git commit, data hash)

  ---
  üìÅ Estructura del Proyecto

  predecir_puntaje_icfes/
  ‚îú‚îÄ‚îÄ api/
  ‚îÇ   ‚îî‚îÄ‚îÄ app.py                      # API FastAPI con 4 endpoints
  ‚îú‚îÄ‚îÄ train_model/
  ‚îÇ   ‚îî‚îÄ‚îÄ train_model.py              # Script de entrenamiento (600 l√≠neas)
  ‚îú‚îÄ‚îÄ utils/
  ‚îÇ   ‚îú‚îÄ‚îÄ data_clean.py               # DataPipeline para limpieza (263 l√≠neas)
  ‚îÇ   ‚îî‚îÄ‚îÄ config.py                   # Config singleton (83 l√≠neas)
  ‚îú‚îÄ‚îÄ data/raw/
  ‚îÇ   ‚îú‚îÄ‚îÄ data_train.csv              # Dataset (~9000 filas, 8.1 MB)
  ‚îÇ   ‚îî‚îÄ‚îÄ data_train.csv.dvc          # Puntero DVC a S3
  ‚îú‚îÄ‚îÄ models/
  ‚îÇ   ‚îú‚îÄ‚îÄ best_model.pkl              # Modelo entrenado (714 KB)
  ‚îÇ   ‚îú‚îÄ‚îÄ model_metadata.pkl          # Metadata del modelo (556 B)
  ‚îÇ   ‚îú‚îÄ‚îÄ best_model.pkl.dvc          # Puntero DVC
  ‚îÇ   ‚îî‚îÄ‚îÄ model_metadata.pkl.dvc      # Puntero DVC
  ‚îú‚îÄ‚îÄ .github/workflows/
  ‚îÇ   ‚îî‚îÄ‚îÄ pipeline.yml                # CI/CD automatizado
  ‚îú‚îÄ‚îÄ .dvc/
  ‚îÇ   ‚îî‚îÄ‚îÄ config                      # Configuraci√≥n S3 remoto
  ‚îú‚îÄ‚îÄ config.yaml                     # Configuraci√≥n centralizada
  ‚îú‚îÄ‚îÄ Dockerfile                      # Containerizaci√≥n
  ‚îú‚îÄ‚îÄ buildspec.yml                   # AWS CodeBuild (alternativo)
  ‚îú‚îÄ‚îÄ requirements.txt                # 170 dependencias Python
  ‚îî‚îÄ‚îÄ README.md                       # Este archivo

  ---
  üî¨ Detalles T√©cnicos

  Algoritmos Evaluados

  | Modelo           | Hiperpar√°metros Optimizados                                                           | Trials | Best
   R¬≤ |
  |------------------|---------------------------------------------------------------------------------------|--------|-----
  ----|
  | RandomForest     | n_estimators, max_depth, min_samples_split/leaf, max_features                         | 50     |
  ~98.4%  |
  | GradientBoosting | n_estimators, max_depth, learning_rate, subsample, min_samples                        | 50     |
  ~98.2%  |
  | XGBoost          | n_estimators, max_depth, learning_rate, subsample, colsample, gamma, reg_alpha/lambda | 50     |
  ~98.1%  |

  Estrategia de selecci√≥n: Mejor R¬≤ score en cross-validation de 5 folds

  Pipeline de Preprocesamiento

  DataPipeline ejecuta:
  1. Carga del CSV crudo
  2. Selecci√≥n de 6 columnas (5 features + 1 target)
  3. Eliminaci√≥n de duplicados
  4. Eliminaci√≥n de valores nulos
  5. Validaci√≥n de rangos (features: 0-100, target: 0-500)
  6. Reset de √≠ndices
  7. Estad√≠sticas descriptivas

  Pipeline del modelo:
  Pipeline([
      ('scaler', StandardScaler()),  # Normalizaci√≥n Z-score
      ('model', RandomForestRegressor(**best_params))
  ])

  M√©tricas Calculadas

  Durante entrenamiento:
  - R¬≤ Score: Coeficiente de determinaci√≥n
  - MAE: Mean Absolute Error
  - RMSE: Root Mean Squared Error
  - MAPE: Mean Absolute Percentage Error

  Cross-validation:
  - 5-fold CV para evaluar generalizaci√≥n
  - Promedio y desviaci√≥n est√°ndar de m√©tricas

  ---
  üåê Endpoints de la API

  | M√©todo | Endpoint  | Descripci√≥n                          | Ejemplo                           |
  |--------|-----------|--------------------------------------|-----------------------------------|
  | GET    | /         | Informaci√≥n general de la API        | curl http://localhost:8000/       |
  | GET    | /health   | Health check (valida modelo cargado) | curl http://localhost:8000/health |
  | POST   | /predict/ | Predicci√≥n de puntaje ICFES          | Ver secci√≥n "Hacer Predicciones"  |
  | GET    | /config   | Configuraci√≥n actual (debugging)     | curl http://localhost:8000/config |
  | GET    | /docs     | Documentaci√≥n Swagger interactiva    | open http://localhost:8000/docs   |

  Caracter√≠sticas de la API:
  - Validaci√≥n autom√°tica con Pydantic
  - Schema din√°mico desde config.yaml
  - Logging estructurado
  - Manejo robusto de errores
  - Validaci√≥n de outputs (0-500)

  ---
  üîÑ CI/CD Pipeline (GitHub Actions)

  Trigger: Push a branch main

  Fases automatizadas:

  1. Setup
     - Checkout c√≥digo
     - Setup Python 3.9
     - Instalar dependencias
     - Configurar credenciales AWS

  2. Data
     - dvc pull (descargar datos desde S3)

  3. Train (CI)
     - Ejecutar train_model.py
     - Generar best_model.pkl

  4. Build (CD)
     - docker build
     - docker push a Docker Hub

  5. Deploy (CD)
     - Trigger webhook de Render
     - Deploy autom√°tico

  Tiempo total: ~8 minutos

  Secretos requeridos:
  - AWS_ACCESS_KEY_ID
  - AWS_SECRET_ACCESS_KEY
  - AWS_REGION
  - DOCKER_USERNAME
  - DOCKER_PASSWORD
  - RENDER_DEPLOY_HOOK

  ---
  üîê Configuraci√≥n de Secretos

  Para DVC (local)

  # Opci√≥n 1: DVC remote config
  dvc remote modify s3_remote access_key_id YOUR_KEY
  dvc remote modify s3_remote secret_access_key YOUR_SECRET

  # Opci√≥n 2: Variables de entorno
  export AWS_ACCESS_KEY_ID=your_key
  export AWS_SECRET_ACCESS_KEY=your_secret
  export AWS_DEFAULT_REGION=us-east-1

  Para GitHub Actions

  Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí New repository secret

  Agregar:
  - AWS_ACCESS_KEY_ID
  - AWS_SECRET_ACCESS_KEY
  - AWS_REGION
  - DOCKER_USERNAME
  - DOCKER_PASSWORD
  - RENDER_DEPLOY_HOOK

  ---
  üß™ Testing y Validaci√≥n

  Test de API en local

  # Health check
  curl http://localhost:8000/health

  # Predicci√≥n v√°lida
  curl -X POST http://localhost:8000/predict/ \
    -H "Content-Type: application/json" \
    -d '{"MOD_RAZONA_CUANTITATIVO_PNAL": 80, "MOD_LECTURA_CRITICA_PNAL": 85, "MOD_COMPETEN_CIUDADA_PNAL": 75, 
  "MOD_INGLES_PNAL": 70, "MOD_COMUNI_ESCRITA_PNAL": 78}'

  # Test de validaci√≥n (debe fallar)
  curl -X POST http://localhost:8000/predict/ \
    -H "Content-Type: application/json" \
    -d '{"MOD_RAZONA_CUANTITATIVO_PNAL": 150}'  # Fuera de rango

  Verificar modelo entrenado

  import joblib

  # Cargar modelo y metadata
  model = joblib.load('models/best_model.pkl')
  metadata = joblib.load('models/model_metadata.pkl')

  print(f"Modelo: {metadata['model_name']}")
  print(f"R¬≤ Score: {metadata['test_r2']:.4f}")
  print(f"MAE: {metadata['test_mae']:.2f}")

  ---
  üêõ Troubleshooting

  Problema: dvc pull falla con error de credenciales

  # Soluci√≥n: Verificar configuraci√≥n
  dvc remote list
  dvc config cache.dir

  # Reconfigurar remoto
  dvc remote modify s3_remote access_key_id YOUR_KEY
  dvc remote modify s3_remote secret_access_key YOUR_SECRET

  # Test de conexi√≥n
  aws s3 ls s3://proyecto-icfes-data/

  Problema: Docker build falla por falta de modelos

  # Soluci√≥n: Descargar modelos antes de build
  dvc pull models/

  # Verificar que existen
  ls -lh models/*.pkl

  # Rebuild
  docker build -t icfes-api .

  Problema: API retorna error 500 al predecir

  # Soluci√≥n: Verificar logs
  docker logs <container_id>

  # Revisar que config.yaml tiene todas las features
  cat config.yaml

  # Probar predicci√≥n con todos los campos
  curl -X POST http://localhost:8000/predict/ \
    -H "Content-Type: application/json" \
    -d '{
      "MOD_RAZONA_CUANTITATIVO_PNAL": 75,
      "MOD_LECTURA_CRITICA_PNAL": 80,
      "MOD_COMPETEN_CIUDADA_PNAL": 70,
      "MOD_INGLES_PNAL": 65,
      "MOD_COMUNI_ESCRITA_PNAL": 72
    }'

  Problema: Entrenamiento falla por memoria

  # Soluci√≥n: Reducir trials de Optuna
  # Editar config.yaml:
  training:
    optuna_trials: 20  # Reducir de 50 a 20

  # O usar menos datos para testing r√°pido

  ---
  üìä Metadata del Modelo

  El archivo model_metadata.pkl contiene:

  {
      "model_name": "RandomForest",
      "cv_r2_mean": 0.984,
      "cv_r2_std": 0.002,
      "test_r2": 0.982,
      "test_mae": 5.23,
      "test_rmse": 7.15,
      "test_mape": 1.85,
      "mlflow_run_id": "abc123...",
      "feature_names": [...],
      "best_params": {...},
      "git_commit": "cadd00e",
      "data_hash": "0def2cc71...",
      "trained_at": "2024-11-18T18:07:00"
  }

  Uso de metadata:
  - Auditor√≠a de modelos en producci√≥n
  - Reproducibilidad (git commit + data hash)
  - Comparaci√≥n de versiones
  - Debugging de performance

  ---
  ü§ù Contribuci√≥n

  Workflow de contribuci√≥n

  # 1. Fork y clonar
  git clone <your-fork-url>
  cd predecir_puntaje_icfes

  # 2. Crear branch
  git checkout -b feature/nueva-funcionalidad

  # 3. Hacer cambios y commit
  git add .
  git commit -m "Add: nueva funcionalidad"

  # 4. Push y crear PR
  git push origin feature/nueva-funcionalidad

  Guidelines

  - Seguir PEP 8 para c√≥digo Python
  - Agregar docstrings a funciones nuevas
  - Actualizar requirements.txt si se agregan dependencias
  - Probar localmente antes de PR
  - Incluir descripci√≥n clara en el PR

  ---
  üìö Recursos Adicionales

  Documentaci√≥n de herramientas:
  - https://dvc.org/doc
  - https://mlflow.org/docs/latest/index.html
  - https://fastapi.tiangolo.com/
  - https://optuna.readthedocs.io/

  Best practices MLOps:
  - https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning
  - https://learn.microsoft.com/en-us/azure/architecture/example-scenario/mlops/mlops-maturity-model

  ---
  üìù Licencia

  Este proyecto es de c√≥digo abierto y est√° disponible bajo la licencia MIT.

  ---
  üë§ Autor

  Edgar Yovany Samaca Acu√±a

  Proyecto desarrollado como demostraci√≥n de habilidades en Machine Learning y MLOps, implementando pipeline completo desde
  experimentaci√≥n hasta deployment en producci√≥n.

  ---
  üéØ Pr√≥ximas Mejoras

  - Feature Store con Feast
  - A/B testing framework
  - Data drift monitoring con Evidently AI
  - Kubernetes deployment con Helm
  - Model registry formal con MLflow
  - Tests automatizados (pytest)
  - Monitoring con Prometheus + Grafana