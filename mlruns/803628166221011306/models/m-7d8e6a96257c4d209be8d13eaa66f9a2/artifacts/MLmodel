artifact_path: file:///Users/giovanysamaca/Desktop/predecir_puntaje_icfes/mlruns/803628166221011306/models/m-7d8e6a96257c4d209be8d13eaa66f9a2/artifacts
flavors:
  python_function:
    env:
      conda: conda.yaml
      virtualenv: python_env.yaml
    loader_module: mlflow.sklearn
    model_path: model.pkl
    predict_fn: predict
    python_version: 3.11.1
  sklearn:
    code: null
    pickled_model: model.pkl
    serialization_format: cloudpickle
    sklearn_version: 1.7.2
is_signature_from_type_hint: false
mlflow_version: 3.6.0
model_id: m-7d8e6a96257c4d209be8d13eaa66f9a2
model_size_bytes: 603724
model_uuid: m-7d8e6a96257c4d209be8d13eaa66f9a2
prompts: null
run_id: c8e282f070494379a7b2629cd92fe4e8
saved_input_example_info:
  artifact_path: input_example.json
  pandas_orient: split
  serving_input_path: serving_input_example.json
  type: dataframe
signature:
  inputs: '[{"type": "long", "name": "MOD_RAZONA_CUANTITATIVO_PNAL", "required": true},
    {"type": "long", "name": "MOD_LECTURA_CRITICA_PNAL", "required": true}, {"type":
    "long", "name": "MOD_COMPETEN_CIUDADA_PNAL", "required": true}, {"type": "long",
    "name": "MOD_INGLES_PNAL", "required": true}, {"type": "double", "name": "MOD_COMUNI_ESCRITA_PNAL",
    "required": true}]'
  outputs: '[{"type": "float", "required": true}]'
  params: null
type_hint_from_example: false
utc_time_created: '2025-11-18 16:42:40.546674'
